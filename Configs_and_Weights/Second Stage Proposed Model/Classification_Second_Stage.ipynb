{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_vMy89lBXsE",
        "outputId": "aa775922-d25e-45a3-cfa0-4f993b4d1f75"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import optuna\n",
        "from tqdm import tqdm\n",
        "import seaborn as sns;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cp3zA-1CGecS",
        "outputId": "401878f8-5f51-4b48-af0b-522e1bdd7c24"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-05-18 13:47:04.558969: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-05-18 13:47:05.214317: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/anaconda3/envs/matheus_levy_tensorflow/lib/python3.10/site-packages/cv2/../../lib64:/usr/local/cuda-11.4/lib64:/usr/local/cuda-11.4/lib64:/usr/local/cuda-11.4/lib64:\n",
            "2024-05-18 13:47:05.214388: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/anaconda3/envs/matheus_levy_tensorflow/lib/python3.10/site-packages/cv2/../../lib64:/usr/local/cuda-11.4/lib64:/usr/local/cuda-11.4/lib64:/usr/local/cuda-11.4/lib64:\n",
            "2024-05-18 13:47:05.214395: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers import Dense, Activation, Flatten, Dropout, GlobalAveragePooling2D, Concatenate, Reshape, GlobalMaxPooling2D, GlobalMaxPooling3D, GlobalAveragePooling3D, Conv2D, Conv1D, Add\n",
        "import random\n",
        "import sklearn\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from keras import optimizers\n",
        "from sklearn.utils import class_weight\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "import cv2\n",
        "import albumentations as A\n",
        "from keras.models import Sequential, Model\n",
        "from keras.models import model_from_json\n",
        "from sklearn.metrics import cohen_kappa_score, roc_auc_score, roc_curve,accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from tqdm import tqdm\n",
        "from keras.applications.densenet import DenseNet169, DenseNet121, DenseNet201\n",
        "from keras.applications.efficientnet import EfficientNetB0, EfficientNetB1, EfficientNetB2, EfficientNetB3, EfficientNetB4, EfficientNetB5, EfficientNetB6, EfficientNetB7\n",
        "from keras.applications.xception import Xception"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "1a13FUF7ApTD"
      },
      "outputs": [],
      "source": [
        "def resize(width, height, img):\n",
        "  altura, largura, _ = img.shape\n",
        "\n",
        "  imagem_redimensionada = img\n",
        "  if (largura > width):\n",
        "    nova_largura = width\n",
        "    altura_original, largura_original = img.shape[:2]\n",
        "    nova_altura = int((nova_largura / largura_original) * altura_original)\n",
        "    imagem_redimensionada = cv2.resize(img, (nova_largura, nova_altura))\n",
        "    altura, largura, _ = imagem_redimensionada.shape\n",
        " \n",
        "\n",
        "  if (altura > height):\n",
        "    nova_altura = height\n",
        "    altura_original, largura_original = imagem_redimensionada.shape[:2]\n",
        "    nova_largura = int((nova_altura / altura_original) * largura_original)\n",
        "    imagem_redimensionada = cv2.resize(imagem_redimensionada, (nova_largura, nova_altura))\n",
        "\n",
        "\n",
        "  delta_largura = width - imagem_redimensionada.shape[1]\n",
        "  delta_altura = height - imagem_redimensionada.shape[0]\n",
        "\n",
        "  # Calcular o preenchimento necessário em cada lado da imagem\n",
        "  top = delta_altura // 2\n",
        "  bottom = delta_altura - top\n",
        "  left = delta_largura // 2\n",
        "  right = delta_largura - left\n",
        "\n",
        "  # Adicionar preenchimento à imagem\n",
        "  img_com_preenchimento = cv2.copyMakeBorder(imagem_redimensionada, top, bottom, left, right, cv2.BORDER_CONSTANT, value=[0, 0, 0])\n",
        "  return img_com_preenchimento\n",
        "\n",
        "def get_json_from_img(filename, path):\n",
        "  filename =  os.path.splitext(filename)[0]\n",
        "  filename += '.json'\n",
        "  with open(os.path.join(path, 'labels', filename), 'r') as openfile:\n",
        "    json_object = json.load(openfile)\n",
        "  return json_object\n",
        "\n",
        "def read_dataset(path):\n",
        "  x, y = [], []\n",
        "  for file in tqdm(os.listdir(os.path.join(path, 'image'))):\n",
        "    img = cv2.imread(os.path.join(path, 'image', file))[...,::-1]\n",
        "    img = resize(128, 128, img)\n",
        "    ann = get_json_from_img(file, path)\n",
        "    label = ann['category_id']\n",
        "    # if label != -1:\n",
        "    x.append(img)\n",
        "    y.append(label)\n",
        "  return np.array(x), np.array(y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 8814/8814 [00:25<00:00, 348.82it/s]\n",
            "100%|██████████| 2208/2208 [00:06<00:00, 355.54it/s]\n",
            "100%|██████████| 2228/2228 [00:06<00:00, 327.62it/s]\n"
          ]
        }
      ],
      "source": [
        "x_train, y_train = read_dataset('/home/matheus_levy/workspace/dataset/Crop_dataset/train')\n",
        "x_val, y_val = read_dataset('/home/matheus_levy/workspace/dataset/Crop_dataset/val')\n",
        "x_test, y_test = read_dataset('/home/matheus_levy/workspace/dataset/Crop_dataset/test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "cFwoZQ4NfTXC"
      },
      "outputs": [],
      "source": [
        "x_train = np.load('/home/matheus_levy/workspace/crops_npy/x_train.npy')\n",
        "y_train = np.load('/home/matheus_levy/workspace/crops_npy/y_train.npy')\n",
        "\n",
        "x_val = np.load('/home/matheus_levy/workspace/crops_npy/x_val.npy')\n",
        "y_val = np.load('/home/matheus_levy/workspace/crops_npy/y_val.npy')\n",
        "\n",
        "x_test = np.load('/home/matheus_levy/workspace/crops_npy/x_test.npy')\n",
        "y_test = np.load('/home/matheus_levy/workspace/crops_npy/y_test.npy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "XVImtnNlIQoH"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ 1  2  3  4  5  6  7  8  9 10 11]\n",
            "[ 1  2  3  4  5  6  7  8  9 10 11]\n",
            "[ 1  2  3  4  5  6  7  8  9 10 11]\n"
          ]
        }
      ],
      "source": [
        "print(np.unique(y_train))\n",
        "print(np.unique(y_val))\n",
        "print(np.unique(y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "5mkyFrqjLgV8"
      },
      "outputs": [],
      "source": [
        "y_train-=1\n",
        "y_val-=1\n",
        "y_test-=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "o2l04GfmOvmH"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ 0  1  2  3  4  5  6  7  8  9 10]\n",
            "[ 0  1  2  3  4  5  6  7  8  9 10]\n",
            "[ 0  1  2  3  4  5  6  7  8  9 10]\n"
          ]
        }
      ],
      "source": [
        "print(np.unique(y_train))\n",
        "print(np.unique(y_val))\n",
        "print(np.unique(y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-05-18 13:47:20.280029: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2024-05-18 13:47:20.312589: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2024-05-18 13:47:20.313053: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2024-05-18 13:47:20.313933: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-05-18 13:47:20.314628: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2024-05-18 13:47:20.315047: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2024-05-18 13:47:20.315450: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2024-05-18 13:47:21.152330: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2024-05-18 13:47:21.152997: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2024-05-18 13:47:21.153396: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2024-05-18 13:47:21.153759: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10214 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
          ]
        }
      ],
      "source": [
        "model = tf.keras.models.load_model('/home/matheus_levy/workspace/classifiers/densenet201.keras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def draw_confusion_matrix(true,preds):\n",
        "    conf_matx = confusion_matrix(true, preds)\n",
        "    sns.heatmap(conf_matx, annot=True,annot_kws={\"size\": 12},fmt='g', cbar=False, cmap=\"viridis\")\n",
        "    plt.show()\n",
        "    print(sklearn.metrics.classification_report(true, preds, digits=5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQMs4WnLqYCZ",
        "outputId": "09f5b603-0aea-4f5a-d25e-c7869ebec5dd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 21%|██        | 554/2625 [02:08<07:47,  4.43it/s]"
          ]
        }
      ],
      "source": [
        "def get_ann_from_image_id(id, coco_preds):\n",
        "  preds = [pred for pred in coco_preds if pred['image_id'] == id]\n",
        "  return preds\n",
        "\n",
        "def match_ann_bbox(bbox, anns_rpn):\n",
        "  for ann_rpn in anns_rpn:\n",
        "    if ann_rpn['bbox'] == bbox:\n",
        "      return ann_rpn\n",
        "\n",
        "# Model prediction\n",
        "# Get the crop (image) and get the label (json)\n",
        "# The prediction label always has category_id == 0 which indicates an object there\n",
        "# Resize the crop (image) and model prediction\n",
        "# Go to the RPN result json (result json)\n",
        "# Get all predictions from the image_id of the current label\n",
        "# Check which one has the same bbox\n",
        "# Change the category_id of this annotation to the predicted category_id\n",
        "crop_path =  '/home/matheus_levy/workspace/dataset/Crops/Cascade_R_CNN/val'\n",
        "path_detection_1_stage = '/home/matheus_levy/workspace/RPN_YOLO_Center_Retina/Cascade_R_CNN/predicts_bbox_cascade_swin_val.json.bbox.json'\n",
        "y_pred = [] \n",
        "y_true = []\n",
        "final_pred = []\n",
        "for filename in tqdm(os.listdir(os.path.join(crop_path, 'images'))):\n",
        "  img = cv2.imread(os.path.join(crop_path, 'images', filename))[...,::-1]\n",
        "  img_crop= resize(128, 128, img)\n",
        "  ann_crop = get_json_from_img(filename, crop_path)\n",
        "  bbox_crop = ann_crop['bbox']\n",
        "  pred_class = model(np.expand_dims(img_crop/255.0, axis=0))\n",
        "  pred_class = np.argmax(pred_class)\n",
        "  y_pred.append(pred_class)\n",
        "  y_true.append(ann_crop['category_id'])\n",
        "  with open(path_detection_1_stage, 'r') as openfile:\n",
        "    coco_pred_rpn = json.load(openfile)\n",
        "  image_id_crop = ann_crop['image_id']\n",
        "  predicts_rpn_anns_for_image_id = get_ann_from_image_id(image_id_crop, coco_pred_rpn)\n",
        "  ann_match = match_ann_bbox(bbox_crop, predicts_rpn_anns_for_image_id)\n",
        "  ann_match['category_id'] = int(pred_class) + 1\n",
        "  final_pred.append(ann_match)\n",
        "\n",
        "with open(\"/home/matheus_levy/workspace/test.json\", \"w\") as outfile:\n",
        "  json.dump(final_pred, outfile, indent=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "draw_confusion_matrix(y_true,y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2260\n"
          ]
        }
      ],
      "source": [
        "with open(path_detection_1_stage, 'r') as openfile:\n",
        "    coco_pred_rpn = json.load(openfile)\n",
        "print(len(coco_pred_rpn))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2260"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(final_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2225/2225 [00:07<00:00, 314.82it/s]\n"
          ]
        }
      ],
      "source": [
        "crop_path = '/home/matheus_levy/workspace/dataset/CenterNet_Crop'\n",
        "x_test, y_test = read_dataset(crop_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2225,)"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2225"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2686/2686 [03:11<00:00, 14.03it/s]\n"
          ]
        }
      ],
      "source": [
        "# 1. Pegar predições\n",
        "# 2. Limite de Score (>=0.5)\n",
        "# 3. Verificar IoU com o GT\n",
        "# 4. Pegar a classe com o GT\n",
        "# 5. Crop da bbox com +10% de expansão\n",
        "# 6. Salvar o crop como imagem e a classe no txt\n",
        "import json\n",
        "import cv2\n",
        "import os \n",
        "import matplotlib.patches as patches\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "# 'train' mode to generate crops to train a classifier\n",
        "# 'pred' mode to generate crops to be classificate by a classifier (do not generate the groundtruth label)\n",
        "mode= 'pred'\n",
        "\n",
        "def get_prediction_from_coco_json(json_path, score_thr=0.0):\n",
        "    with open(json_path, 'r') as openfile:\n",
        "        coco_json_result = json.load(openfile)\n",
        "    if mode == 'train':\n",
        "        return coco_json_result['annotations']\n",
        "    else:\n",
        "        return [pred for pred in coco_json_result if pred['score'] > score_thr]\n",
        "\n",
        "def get_coco_json(gt_path=r\"/home/matheus_levy/workspace/dataset/mdetection_dataset/test/1_class_annotation.coco.json\"):\n",
        "    with open(gt_path, 'r') as openfile:\n",
        "        coco_json_gt = json.load(openfile)\n",
        "    return coco_json_gt\n",
        "\n",
        "def calculate_iou(box1, box2):\n",
        "    x1, y1, w1, h1 = box1[0], box1[1], box1[2], box1[3]\n",
        "    x2, y2, w2, h2 = box2[0], box2[1], box2[2], box2[3]\n",
        "\n",
        "    x_inter = max(x1, x2)\n",
        "    y_inter = max(y1, y2)\n",
        "    w_inter = max(0, min(x1 + w1, x2 + w2) - x_inter)\n",
        "    h_inter = max(0, min(y1 + h1, y2 + h2) - y_inter)\n",
        "\n",
        "    area_inter = w_inter * h_inter\n",
        "    area_union = w1 * h1 + w2 * h2 - area_inter\n",
        "\n",
        "    iou = area_inter / area_union\n",
        "    return iou\n",
        "\n",
        "def get_ann_from_image_id(id, coco_preds, coco_gts):\n",
        "    preds = [pred for pred in coco_preds if pred['image_id'] == id]\n",
        "    if mode == 'pred':\n",
        "        gts = [gt for gt in coco_gts if gt['image_id'] == id]\n",
        "    else:\n",
        "        gts = None\n",
        "    return preds, gts\n",
        "\n",
        "def match_preds_with_gt(preds, gts, iou_thr=0.5):\n",
        "    for pred in preds:\n",
        "        pred_bbox = pred['bbox']\n",
        "        best_iou = 0\n",
        "        best_ann = None\n",
        "        for gt in gts:\n",
        "            gt_bbox = gt['bbox']\n",
        "            iou = calculate_iou(pred_bbox, gt_bbox)\n",
        "            if iou > best_iou:\n",
        "                best_iou = iou\n",
        "                best_ann = gt\n",
        "        if best_ann is not None:\n",
        "            pred['category_id'] = best_ann['category_id']\n",
        "        else:\n",
        "            pred['category_id'] = -1\n",
        "    return preds\n",
        "\n",
        "def qtd_imagens_in_results(coco_preds):\n",
        "    image_ids = set()\n",
        "    for prediction in coco_preds:\n",
        "        image_id = prediction['image_id']\n",
        "        image_ids.add(image_id)\n",
        "    return len(image_ids)\n",
        "\n",
        "def qtd_imagens_in_gt(coco_gt):\n",
        "    imagens = coco_gt['images']\n",
        "    return len(imagens)\n",
        "\n",
        "\n",
        "def image_id_to_name(id, coco_gt):\n",
        "    imagens = coco_gt['images']\n",
        "    for imagem in imagens:\n",
        "        if imagem['id'] == id:\n",
        "            return imagem['file_name']\n",
        "\n",
        "def imagem_by_id(id, coco_gt, path_to_image):\n",
        "    file_name = image_id_to_name(id, coco_gt)\n",
        "    img = cv2.imread(os.path.join(path_to_image, file_name))\n",
        "    return img\n",
        "\n",
        "def crop_imagem(imagem, bbox, aumento=0.3):\n",
        "    x,y, largura, altura = bbox[0], bbox[1], bbox[2], bbox[3]\n",
        "    aumento_largura = largura * aumento\n",
        "    aumento_altura = altura * aumento\n",
        "    x -= aumento_largura / 2  # Subtrai metade do aumento da largura do ponto x\n",
        "    y -= aumento_altura / 2   # Subtrai metade do aumento da altura do ponto y\n",
        "    if (x<0):\n",
        "        x=0\n",
        "    if (y<0):\n",
        "        y=0\n",
        "    largura += aumento_largura  # Aumenta a largura\n",
        "    altura += aumento_altura    # Aumenta a altura\n",
        "    x,y, largura, altura = int(x), int(y), int(largura), int(altura)\n",
        "    return imagem[y:y+altura, x:x+largura]\n",
        "    \n",
        "json_path = r'/home/matheus_levy/workspace/RPN_YOLO_Center_Retina/Cascade_R_CNN/predicts_bbox_cascade_swin.json.bbox.json'\n",
        "save_crop_image_path = r\"/home/matheus_levy/workspace/dataset/Crops/Cascade_R_CNN/test/images\"\n",
        "save_crop_label_path = r\"/home/matheus_levy/workspace/dataset/Crops/Cascade_R_CNN/test/labels\"\n",
        "\n",
        "preds = get_prediction_from_coco_json(json_path) # Durante o treino é o proprio gt\n",
        "gts = get_coco_json()\n",
        "if mode == 'pred':\n",
        "    qtd_imagens = qtd_imagens_in_gt(gts)\n",
        "if mode == 'train':\n",
        "    qtd_imagens = len(preds)\n",
        "preds_classes = []\n",
        "\n",
        "for i in range(qtd_imagens):\n",
        "    p, g = get_ann_from_image_id(i, preds, gts['annotations'])\n",
        "    if mode == 'pred':\n",
        "        ps = match_preds_with_gt(p, g)\n",
        "        preds_classes.extend(ps)\n",
        "    else:\n",
        "        preds_classes.extend(p)\n",
        "\n",
        "with open(\"retina_without_thr.json\", \"w\") as outfile:\n",
        "    json.dump(preds_classes, outfile, indent=2)\n",
        "\n",
        "i=0\n",
        "for pred in tqdm(preds_classes):\n",
        "    imagem = imagem_by_id(pred['image_id'],\n",
        "    gts, path_to_image=r\"/home/matheus_levy/workspace/dataset/mdetection_dataset/test\")\n",
        "    crop = crop_imagem(imagem, pred['bbox'])\n",
        "    if crop.size == 0:\n",
        "        continue\n",
        "    coco_bbox = pred[\"bbox\"]\n",
        "    x, y, largura, altura = coco_bbox\n",
        "\n",
        "    cv2.imwrite(os.path.join(save_crop_image_path, f\"{i}.png\"), crop)\n",
        "    if mode == 'train':\n",
        "        json_label = {\"image_id\": pred['image_id'], \n",
        "                  \"category_id\": pred[\"category_id\"],\n",
        "                  \"bbox\": pred[\"bbox\"], \n",
        "                  } \n",
        "    else:\n",
        "        json_label = {\"image_id\": pred['image_id'], \n",
        "                    \"category_id\": pred[\"category_id\"],\n",
        "                    \"bbox\": pred[\"bbox\"],\n",
        "                    \"score\": pred[\"score\"]\n",
        "                    } \n",
        "    with open(f\"{save_crop_label_path}/{i}.json\", \"w\") as outfile:\n",
        "        json.dump(json_label, outfile, indent=2)\n",
        "    i+=1"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
